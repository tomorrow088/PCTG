"""
åŒé‡å¯¹æŠ—æŸå¤±å‡½æ•°
Dual Adversarial Loss - åŒæ—¶å¯¹æŠ—äººçœ¼å’ŒAIæ£€æµ‹

æ ¸å¿ƒåŠŸèƒ½:
1. AIæ£€æµ‹å™¨å¯¹æŠ— (SINet + CLIP)
2. äººçœ¼è§†è§‰å¯¹æŠ— (è½®å»“ + æ˜¾è‘—æ€§ + é¢œè‰²)
3. è‡ªé€‚åº”æƒé‡å¹³è¡¡
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import cv2
import numpy as np
from typing import Dict, Tuple, Optional


class ContourSuppressionLoss(nn.Module):
    """
    è½®å»“æŠ‘åˆ¶æŸå¤±
    ç›®æ ‡: ç ´åç›®æ ‡åŒºåŸŸçš„è¾¹ç¼˜æ¸…æ™°åº¦ï¼Œä½¿äººçœ¼éš¾ä»¥è¯†åˆ«è½®å»“
    """
    
    def __init__(self):
        super().__init__()
        
        # Sobelç®—å­ (è¾¹ç¼˜æ£€æµ‹)
        sobel_x = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=torch.float32)
        sobel_y = torch.tensor([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=torch.float32)
        
        self.register_buffer('sobel_x', sobel_x.view(1, 1, 3, 3))
        self.register_buffer('sobel_y', sobel_y.view(1, 1, 3, 3))
    
    def forward(self, image: torch.Tensor, mask: torch.Tensor) -> torch.Tensor:
        """
        Args:
            image: [B, 3, H, W] ç”Ÿæˆçš„å›¾åƒ
            mask: [B, 1, H, W] ç›®æ ‡æ©ç 
            
        Returns:
            loss: è½®å»“æŠ‘åˆ¶æŸå¤±
        """
        # è½¬æ¢ä¸ºç°åº¦å›¾
        gray = 0.299 * image[:, 0:1] + 0.587 * image[:, 1:2] + 0.114 * image[:, 2:3]
        
        # Sobelè¾¹ç¼˜æ£€æµ‹
        edge_x = F.conv2d(gray, self.sobel_x, padding=1)
        edge_y = F.conv2d(gray, self.sobel_y, padding=1)
        
        # è¾¹ç¼˜å¼ºåº¦
        edge_magnitude = torch.sqrt(edge_x**2 + edge_y**2 + 1e-8)
        
        # åªåœ¨æ©ç åŒºåŸŸå†…è®¡ç®—
        masked_edges = edge_magnitude * mask
        
        # æŸå¤±: æœ€å°åŒ–æ©ç åŒºåŸŸçš„è¾¹ç¼˜å¼ºåº¦
        loss = masked_edges.mean()
        
        return loss


class HumanSaliencyLoss(nn.Module):
    """
    äººçœ¼æ˜¾è‘—æ€§æŸå¤±
    åŸºäºç®€åŒ–çš„æ˜¾è‘—æ€§æ£€æµ‹ç®—æ³•
    """
    
    def __init__(self):
        super().__init__()
        
        # é«˜æ–¯æ»¤æ³¢å™¨ï¼ˆç”¨äºå¤šå°ºåº¦æ˜¾è‘—æ€§ï¼‰
        self.gaussian_kernel = self._create_gaussian_kernel(kernel_size=5, sigma=1.0)
    
    def _create_gaussian_kernel(self, kernel_size: int, sigma: float) -> torch.Tensor:
        """åˆ›å»ºé«˜æ–¯æ ¸"""
        x = torch.arange(kernel_size) - kernel_size // 2
        gauss = torch.exp(-x**2 / (2 * sigma**2))
        gauss = gauss / gauss.sum()
        
        kernel = gauss.unsqueeze(0) * gauss.unsqueeze(1)
        kernel = kernel / kernel.sum()
        
        return kernel.view(1, 1, kernel_size, kernel_size)
    
    def forward(self, image: torch.Tensor, mask: torch.Tensor) -> torch.Tensor:
        """
        Args:
            image: [B, 3, H, W] ç”Ÿæˆçš„å›¾åƒ
            mask: [B, 1, H, W] ç›®æ ‡æ©ç 
            
        Returns:
            loss: äººçœ¼æ˜¾è‘—æ€§æŸå¤±
        """
        # è®¡ç®—å±€éƒ¨å¯¹æ¯”åº¦ï¼ˆç®€åŒ–çš„æ˜¾è‘—æ€§ï¼‰
        saliency_map = self._compute_local_contrast(image)
        
        # åªåœ¨æ©ç åŒºåŸŸå†…è®¡ç®—
        masked_saliency = saliency_map * mask
        
        # æŸå¤±: é™ä½æ©ç åŒºåŸŸçš„æ˜¾è‘—æ€§
        loss = masked_saliency.mean()
        
        return loss
    
    def _compute_local_contrast(self, image: torch.Tensor) -> torch.Tensor:
        """è®¡ç®—å±€éƒ¨å¯¹æ¯”åº¦ä½œä¸ºæ˜¾è‘—æ€§æŒ‡æ ‡"""
        # è½¬æ¢ä¸ºLabè‰²å½©ç©ºé—´çš„Lé€šé“ï¼ˆç®€åŒ–ä¸ºç°åº¦ï¼‰
        gray = 0.299 * image[:, 0:1] + 0.587 * image[:, 1:2] + 0.114 * image[:, 2:3]
        
        # é«˜æ–¯æ»¤æ³¢è·å¾—å±€éƒ¨å¹³å‡
        if not hasattr(self, 'gaussian_kernel') or self.gaussian_kernel.device != image.device:
            self.gaussian_kernel = self._create_gaussian_kernel(5, 1.0).to(image.device)
        
        local_mean = F.conv2d(gray, self.gaussian_kernel.expand(1, 1, -1, -1), padding=2)
        
        # å±€éƒ¨å¯¹æ¯”åº¦ = |åƒç´ å€¼ - å±€éƒ¨å¹³å‡|
        local_contrast = torch.abs(gray - local_mean)
        
        return local_contrast


class ColorCamouflageLoss(nn.Module):
    """
    é¢œè‰²ä¼ªè£…æŸå¤±
    ä½¿ç›®æ ‡åŒºåŸŸé¢œè‰²ä¸èƒŒæ™¯èåˆ
    """
    
    def __init__(self, num_bins: int = 64):
        super().__init__()
        self.num_bins = num_bins
    
    def forward(self, generated: torch.Tensor, 
                original: torch.Tensor, 
                mask: torch.Tensor) -> torch.Tensor:
        """
        Args:
            generated: [B, 3, H, W] ç”Ÿæˆçš„å›¾åƒ
            original: [B, 3, H, W] åŸå§‹å›¾åƒ
            mask: [B, 1, H, W] ç›®æ ‡æ©ç 
            
        Returns:
            loss: é¢œè‰²ä¼ªè£…æŸå¤±
        """
        # æå–èƒŒæ™¯å’Œç›®æ ‡åŒºåŸŸ
        background_mask = 1 - mask
        background_colors = original * background_mask
        target_colors = generated * mask
        
        # è®¡ç®—é¢œè‰²åˆ†å¸ƒç»Ÿè®¡
        bg_mean, bg_std = self._compute_color_statistics(background_colors, background_mask)
        target_mean, target_std = self._compute_color_statistics(target_colors, mask)
        
        # æŸå¤±: ç›®æ ‡åŒºåŸŸé¢œè‰²åˆ†å¸ƒæ¥è¿‘èƒŒæ™¯
        mean_loss = F.mse_loss(target_mean, bg_mean)
        std_loss = F.mse_loss(target_std, bg_std)
        
        total_loss = mean_loss + 0.5 * std_loss
        
        return total_loss
    
    def _compute_color_statistics(self, image: torch.Tensor, 
                                  mask: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """è®¡ç®—åŒºåŸŸå†…çš„é¢œè‰²ç»Ÿè®¡"""
        # å±•å¹³ç©ºé—´ç»´åº¦
        B, C, H, W = image.shape
        image_flat = image.view(B, C, -1)  # [B, 3, H*W]
        mask_flat = mask.view(B, 1, -1)    # [B, 1, H*W]
        
        # åªç»Ÿè®¡æ©ç åŒºåŸŸ
        masked_pixels = image_flat * mask_flat
        num_pixels = mask_flat.sum(dim=2, keepdim=True).clamp(min=1)
        
        # å‡å€¼
        mean = masked_pixels.sum(dim=2) / num_pixels.squeeze(-1)  # [B, 3]
        
        # æ ‡å‡†å·®
        variance = ((masked_pixels - mean.unsqueeze(-1))**2 * mask_flat).sum(dim=2) / num_pixels.squeeze(-1)
        std = torch.sqrt(variance + 1e-8)  # [B, 3]
        
        return mean, std


class TextureContinuityLoss(nn.Module):
    """
    çº¹ç†è¿ç»­æ€§æŸå¤±
    ç¡®ä¿ç›®æ ‡åŒºåŸŸè¾¹ç•Œä¸èƒŒæ™¯çº¹ç†å¹³æ»‘è¿‡æ¸¡
    """
    
    def __init__(self, boundary_width: int = 5):
        super().__init__()
        self.boundary_width = boundary_width
    
    def forward(self, generated: torch.Tensor, 
                original: torch.Tensor,
                mask: torch.Tensor) -> torch.Tensor:
        """
        Args:
            generated: [B, 3, H, W] ç”Ÿæˆçš„å›¾åƒ
            original: [B, 3, H, W] åŸå§‹å›¾åƒ
            mask: [B, 1, H, W] ç›®æ ‡æ©ç 
            
        Returns:
            loss: è¾¹ç•Œå¹³æ»‘æŸå¤±
        """
        # æå–è¾¹ç•ŒåŒºåŸŸ
        boundary_mask = self._extract_boundary(mask)
        
        # åœ¨è¾¹ç•ŒåŒºåŸŸè®¡ç®—ç”Ÿæˆå›¾åƒå’ŒåŸå›¾çš„æ¢¯åº¦
        gen_grad = self._compute_gradient(generated)
        orig_grad = self._compute_gradient(original)
        
        # è¾¹ç•ŒåŒºåŸŸçš„æ¢¯åº¦åº”è¯¥ç›¸ä¼¼
        boundary_grad_loss = F.mse_loss(
            gen_grad * boundary_mask,
            orig_grad * boundary_mask
        )
        
        return boundary_grad_loss
    
    def _extract_boundary(self, mask: torch.Tensor) -> torch.Tensor:
        """æå–æ©ç è¾¹ç•Œ"""
        # è†¨èƒ€
        dilated = F.max_pool2d(mask, kernel_size=3, stride=1, padding=1)
        # è…èš€
        eroded = -F.max_pool2d(-mask, kernel_size=3, stride=1, padding=1)
        # è¾¹ç•Œ = è†¨èƒ€ - è…èš€
        boundary = dilated - eroded
        
        return boundary
    
    def _compute_gradient(self, image: torch.Tensor) -> torch.Tensor:
        """è®¡ç®—å›¾åƒæ¢¯åº¦"""
        grad_x = image[:, :, :, 1:] - image[:, :, :, :-1]
        grad_y = image[:, :, 1:, :] - image[:, :, :-1, :]
        
        # Padding to match original size
        grad_x = F.pad(grad_x, (0, 1, 0, 0))
        grad_y = F.pad(grad_y, (0, 0, 0, 1))
        
        gradient = torch.sqrt(grad_x**2 + grad_y**2 + 1e-8)
        
        return gradient


class DualAdversarialLoss(nn.Module):
    """
    åŒé‡å¯¹æŠ—æŸå¤± - ä¸»ç±»
    
    æ•´åˆAIå¯¹æŠ—å’Œäººçœ¼å¯¹æŠ—
    """
    
    def __init__(self, 
                 ai_weight: float = 1.0,
                 human_weight: float = 0.7,
                 contour_weight: float = 0.5,
                 saliency_weight: float = 0.5,
                 color_weight: float = 0.3,
                 texture_weight: float = 0.2):
        """
        Args:
            ai_weight: AIå¯¹æŠ—æ€»æƒé‡
            human_weight: äººçœ¼å¯¹æŠ—æ€»æƒé‡
            contour_weight: è½®å»“æŠ‘åˆ¶æƒé‡
            saliency_weight: æ˜¾è‘—æ€§é™ä½æƒé‡
            color_weight: é¢œè‰²ä¼ªè£…æƒé‡
            texture_weight: çº¹ç†è¿ç»­æ€§æƒé‡
        """
        super().__init__()
        
        # æƒé‡
        self.ai_weight = ai_weight
        self.human_weight = human_weight
        
        # AIå¯¹æŠ—æŸå¤±ï¼ˆåœ¨ä¸»æŸå¤±å‡½æ•°ä¸­è®¡ç®—ï¼‰
        # è¿™é‡Œåªå®šä¹‰äººçœ¼å¯¹æŠ—æŸå¤±
        
        # äººçœ¼å¯¹æŠ—æŸå¤±ç»„ä»¶
        self.contour_loss = ContourSuppressionLoss()
        self.saliency_loss = HumanSaliencyLoss()
        self.color_loss = ColorCamouflageLoss()
        self.texture_loss = TextureContinuityLoss()
        
        # ç»„ä»¶æƒé‡
        self.contour_weight = contour_weight
        self.saliency_weight = saliency_weight
        self.color_weight = color_weight
        self.texture_weight = texture_weight
        
        print(f"âœ… åŒé‡å¯¹æŠ—æŸå¤±åˆå§‹åŒ–")
        print(f"   AIæƒé‡: {ai_weight}, äººçœ¼æƒé‡: {human_weight}")
        print(f"   è½®å»“: {contour_weight}, æ˜¾è‘—æ€§: {saliency_weight}")
        print(f"   é¢œè‰²: {color_weight}, çº¹ç†: {texture_weight}")
    
    def compute_human_adversarial_loss(self, 
                                       generated: torch.Tensor,
                                       original: torch.Tensor,
                                       mask: torch.Tensor) -> Dict[str, torch.Tensor]:
        """
        è®¡ç®—äººçœ¼å¯¹æŠ—æŸå¤±
        
        Args:
            generated: [B, 3, H, W] ç”Ÿæˆçš„å›¾åƒ
            original: [B, 3, H, W] åŸå§‹å›¾åƒ
            mask: [B, 1, H, W] ç›®æ ‡æ©ç 
            
        Returns:
            losses: æŸå¤±å­—å…¸
        """
        losses = {}
        
        # 1. è½®å»“æŠ‘åˆ¶
        contour_loss = self.contour_loss(generated, mask)
        losses['contour_suppression'] = contour_loss
        
        # 2. äººçœ¼æ˜¾è‘—æ€§é™ä½
        saliency_loss = self.saliency_loss(generated, mask)
        losses['human_saliency'] = saliency_loss
        
        # 3. é¢œè‰²ä¼ªè£…
        color_loss = self.color_loss(generated, original, mask)
        losses['color_camouflage'] = color_loss
        
        # 4. çº¹ç†è¿ç»­æ€§
        texture_loss = self.texture_loss(generated, original, mask)
        losses['texture_continuity'] = texture_loss
        
        # æ€»äººçœ¼å¯¹æŠ—æŸå¤±
        total_human_loss = (
            self.contour_weight * contour_loss +
            self.saliency_weight * saliency_loss +
            self.color_weight * color_loss +
            self.texture_weight * texture_loss
        )
        
        losses['total_human_adversarial'] = total_human_loss
        
        return losses
    
    def forward(self,
                generated: torch.Tensor,
                original: torch.Tensor,
                mask: torch.Tensor,
                ai_losses: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:
        """
        è®¡ç®—å®Œæ•´çš„åŒé‡å¯¹æŠ—æŸå¤±
        
        Args:
            generated: [B, 3, H, W] ç”Ÿæˆçš„å›¾åƒ
            original: [B, 3, H, W] åŸå§‹å›¾åƒ
            mask: [B, 1, H, W] ç›®æ ‡æ©ç 
            ai_losses: AIæ£€æµ‹å™¨çš„å¯¹æŠ—æŸå¤±
            
        Returns:
            all_losses: å®Œæ•´æŸå¤±å­—å…¸
        """
        all_losses = {}
        
        # 1. AIå¯¹æŠ—æŸå¤±ï¼ˆå·²åœ¨å¤–éƒ¨è®¡ç®—ï¼‰
        ai_adv_loss = ai_losses.get('total_adversarial_loss', torch.tensor(0.0))
        all_losses['ai_adversarial'] = ai_adv_loss
        all_losses.update({f"ai_{k}": v for k, v in ai_losses.items()})
        
        # 2. äººçœ¼å¯¹æŠ—æŸå¤±
        human_losses = self.compute_human_adversarial_loss(
            generated, original, mask
        )
        all_losses.update({f"human_{k}": v for k, v in human_losses.items()})
        
        # 3. æ€»æŸå¤±
        total_dual_loss = (
            self.ai_weight * ai_adv_loss +
            self.human_weight * human_losses['total_human_adversarial']
        )
        
        all_losses['total_dual_adversarial_loss'] = total_dual_loss
        
        return all_losses
    
    def get_metrics(self, 
                   generated: torch.Tensor,
                   original: torch.Tensor,
                   mask: torch.Tensor) -> Dict[str, float]:
        """
        è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        
        Args:
            generated: [B, 3, H, W] ç”Ÿæˆçš„å›¾åƒ
            original: [B, 3, H, W] åŸå§‹å›¾åƒ
            mask: [B, 1, H, W] ç›®æ ‡æ©ç 
            
        Returns:
            metrics: æŒ‡æ ‡å­—å…¸
        """
        metrics = {}
        
        with torch.no_grad():
            # è¾¹ç¼˜å¼ºåº¦
            gray = 0.299 * generated[:, 0:1] + 0.587 * generated[:, 1:2] + 0.114 * generated[:, 2:3]
            sobel_x = F.conv2d(gray, self.contour_loss.sobel_x, padding=1)
            sobel_y = F.conv2d(gray, self.contour_loss.sobel_y, padding=1)
            edge_strength = torch.sqrt(sobel_x**2 + sobel_y**2 + 1e-8)
            masked_edge_strength = (edge_strength * mask).sum() / mask.sum()
            metrics['edge_strength'] = masked_edge_strength.item()
            
            # æ˜¾è‘—æ€§
            saliency = self.saliency_loss._compute_local_contrast(generated)
            masked_saliency = (saliency * mask).sum() / mask.sum()
            metrics['saliency_level'] = masked_saliency.item()
            
            # é¢œè‰²å·®å¼‚
            bg_mask = 1 - mask
            bg_mean = (original * bg_mask).sum(dim=[2, 3]) / bg_mask.sum(dim=[2, 3]).clamp(min=1)
            target_mean = (generated * mask).sum(dim=[2, 3]) / mask.sum(dim=[2, 3]).clamp(min=1)
            color_distance = torch.norm(bg_mean - target_mean, dim=1).mean()
            metrics['color_distance'] = color_distance.item()
        
        return metrics


# ============================================================
# å·¥å…·å‡½æ•°ï¼šé›†æˆåˆ°ç°æœ‰è®­ç»ƒæµç¨‹
# ============================================================

def integrate_dual_adversarial_loss(composite_loss, config):
    """
    å°†åŒé‡å¯¹æŠ—æŸå¤±é›†æˆåˆ°ç°æœ‰çš„CompositeLossä¸­
    
    Args:
        composite_loss: ç°æœ‰çš„CompositeLosså®ä¾‹
        config: é…ç½®å­—å…¸
        
    Returns:
        enhanced_loss: å¢å¼ºåçš„æŸå¤±å‡½æ•°
    """
    # åˆ›å»ºåŒé‡å¯¹æŠ—æŸå¤±
    dual_adv_loss = DualAdversarialLoss(
        ai_weight=config.get('ai_weight', 1.0),
        human_weight=config.get('human_weight', 0.7),
        contour_weight=config.get('contour_weight', 0.5),
        saliency_weight=config.get('saliency_weight', 0.5),
        color_weight=config.get('color_weight', 0.3),
        texture_weight=config.get('texture_weight', 0.2)
    )
    
    # å°†å…¶æ·»åŠ åˆ°composite_loss
    composite_loss.dual_adversarial_loss = dual_adv_loss
    
    return composite_loss


def compute_dual_adversarial_loss_wrapper(predictions, targets, composite_loss):
    """
    è®¡ç®—åŒ…å«åŒé‡å¯¹æŠ—çš„å®Œæ•´æŸå¤±
    
    åœ¨trainer.pyçš„_train_stepä¸­ä½¿ç”¨
    """
    # 1. è®¡ç®—åŸæœ‰æŸå¤±ï¼ˆåŒ…å«AIå¯¹æŠ—ï¼‰
    original_losses = composite_loss(predictions, targets)
    
    # 2. æå–AIå¯¹æŠ—æŸå¤±
    ai_losses = {
        'total_adversarial_loss': original_losses.get('total_adversarial_loss', torch.tensor(0.0)),
        'sinet_adv_loss': original_losses.get('sinet_adv_loss', torch.tensor(0.0)),
        'clip_adv_loss': original_losses.get('clip_adv_loss', torch.tensor(0.0))
    }
    
    # 3. è®¡ç®—åŒé‡å¯¹æŠ—æŸå¤±
    if hasattr(composite_loss, 'dual_adversarial_loss'):
        dual_losses = composite_loss.dual_adversarial_loss(
            generated=predictions['generated_image'],
            original=targets['original_image'],
            mask=targets['mask'],
            ai_losses=ai_losses
        )
        
        # 4. åˆå¹¶æŸå¤±
        original_losses.update(dual_losses)
        
        # 5. æ›´æ–°æ€»æŸå¤±
        original_losses['total_loss'] = (
            original_losses['total_loss'] - ai_losses['total_adversarial_loss'] +
            dual_losses['total_dual_adversarial_loss']
        )
    
    return original_losses


if __name__ == "__main__":
    # æµ‹è¯•åŒé‡å¯¹æŠ—æŸå¤±
    print("ğŸ§ª æµ‹è¯•åŒé‡å¯¹æŠ—æŸå¤±...")
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    B, C, H, W = 2, 3, 256, 256
    generated = torch.randn(B, C, H, W).to(device)
    original = torch.randn(B, C, H, W).to(device)
    mask = torch.randint(0, 2, (B, 1, H, W)).float().to(device)
    
    # åˆ›å»ºåŒé‡å¯¹æŠ—æŸå¤±
    dual_loss = DualAdversarialLoss(
        ai_weight=1.0,
        human_weight=0.7
    ).to(device)
    
    # æ¨¡æ‹ŸAIæŸå¤±
    ai_losses = {
        'total_adversarial_loss': torch.tensor(0.5).to(device),
        'sinet_adv_loss': torch.tensor(0.3).to(device),
        'clip_adv_loss': torch.tensor(0.2).to(device)
    }
    
    # è®¡ç®—æŸå¤±
    all_losses = dual_loss(generated, original, mask, ai_losses)
    
    print("âœ… åŒé‡å¯¹æŠ—æŸå¤±æµ‹è¯•æˆåŠŸ")
    print("æŸå¤±ç»„ä»¶:")
    for key, value in all_losses.items():
        if isinstance(value, torch.Tensor):
            print(f"  {key}: {value.item():.4f}")
    
    # è®¡ç®—æŒ‡æ ‡
    metrics = dual_loss.get_metrics(generated, original, mask)
    print("\nè¯„ä¼°æŒ‡æ ‡:")
    for key, value in metrics.items():
        print(f"  {key}: {value:.4f}")
