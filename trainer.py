"""
è®­ç»ƒå™¨æ¨¡å—
Adversarial Camouflage Training with SINet

æ ¸å¿ƒåŠŸèƒ½:
1. ç«¯åˆ°ç«¯å¯¹æŠ—è®­ç»ƒæµç¨‹
2. å¤šæ£€æµ‹å™¨è”åˆä¼˜åŒ–  
3. ç‰©ç†çº¦æŸä¸‹çš„çº¹ç†ç”Ÿæˆ
4. å¯è§†åŒ–ä¸è¯„ä¼°
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP

import os
import time
import numpy as np
from typing import Dict, List, Tuple, Optional, Any
from tqdm import tqdm
import matplotlib.pyplot as plt
from pathlib import Path

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from pctg_generator import PCTGGenerator
from sinet_detector import SINetDetector, load_pretrained_sinet
from losses import CompositeLoss
from model_config import TrainingConfig, get_default_config


class AdversarialTrainer:
    """
    å¯¹æŠ—æ€§è¿·å½©è®­ç»ƒå™¨
    
    æ ¸å¿ƒè®­ç»ƒæµç¨‹:
    1. ç”Ÿæˆè¿·å½©çº¹ç†
    2. å¤šæ£€æµ‹å™¨è¯„ä¼°  
    3. åå‘ä¼ æ’­ä¼˜åŒ–
    4. ç‰©ç†çº¦æŸéªŒè¯
    """
    
    def __init__(self, config=None, device='cuda', distributed=False):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨
        
        Args:
            config: è®­ç»ƒé…ç½®
            device: è®­ç»ƒè®¾å¤‡
            distributed: æ˜¯å¦åˆ†å¸ƒå¼è®­ç»ƒ
        """
        self.device = device
        self.distributed = distributed
        
        # é…ç½®
        if config is None:
            config = get_default_config()
        self.config = config
        self.training_config = config['training']
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir = Path("./outputs")
        self.checkpoint_dir = self.output_dir / "checkpoints"
        self.log_dir = self.output_dir / "logs"
        self.vis_dir = self.output_dir / "visualizations"
        
        for dir_path in [self.output_dir, self.checkpoint_dir, self.log_dir, self.vis_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)
        
        # åˆå§‹åŒ–æ¨¡å‹
        self._initialize_models()
        
        # åˆå§‹åŒ–ä¼˜åŒ–å™¨
        self._initialize_optimizers()
        
        # åˆå§‹åŒ–æŸå¤±å‡½æ•°
        self._initialize_losses()
        
        # åˆå§‹åŒ–è®°å½•å™¨
        self._initialize_logging()
        
        # è®­ç»ƒçŠ¶æ€
        self.current_epoch = 0
        self.best_metric = 0.0
        self.training_stats = []
        
        print(f"âœ… è®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   è®¾å¤‡: {self.device}")
        print(f"   åˆ†å¸ƒå¼: {self.distributed}")
        print(f"   è¾“å‡ºç›®å½•: {self.output_dir}")
    
    def _initialize_models(self):
        """åˆå§‹åŒ–æ¨¡å‹"""
        print("ğŸ“¦ åˆå§‹åŒ–æ¨¡å‹...")
        
        # 1. PCTGç”Ÿæˆå™¨
        self.generator = PCTGGenerator(self.config['pctg']).to(self.device)
        
        # 2. SINetæ£€æµ‹å™¨
        self.sinet_detector = load_pretrained_sinet(
            self.config['sinet'].pretrained_path,
            self.device
        )
        self.sinet_detector.eval()  # æ£€æµ‹å™¨ä¿æŒè¯„ä¼°æ¨¡å¼
        
        # 3. CLIPæ£€æµ‹å™¨ (å¯é€‰)
        self.clip_detector = None
        if 'clip' in self.config['multi_detector'].detector_types:
            self.clip_detector = self._load_clip_detector()
        
        # åˆ†å¸ƒå¼è®­ç»ƒè®¾ç½®
        if self.distributed:
            self.generator = DDP(self.generator, device_ids=[self.device])
        
        # è®¡ç®—å‚æ•°é‡
        generator_params = sum(p.numel() for p in self.generator.parameters())
        print(f"   ç”Ÿæˆå™¨å‚æ•°é‡: {generator_params / 1e6:.1f}M")
    
    def _load_clip_detector(self):
        """åŠ è½½CLIPæ£€æµ‹å™¨"""
        try:
            import clip
            model, preprocess = clip.load(
                self.config['clip'].model_name, 
                device=self.device
            )
            model.eval()
            
            # åŒ…è£…CLIPæ£€æµ‹å™¨
            clip_detector = CLIPDetectorWrapper(
                model, preprocess, self.config['clip']
            )
            
            print(f"   âœ… CLIPæ£€æµ‹å™¨åŠ è½½æˆåŠŸ: {self.config['clip'].model_name}")
            return clip_detector
            
        except ImportError:
            print("   âš ï¸ CLIPæœªå®‰è£…ï¼Œè·³è¿‡CLIPæ£€æµ‹å™¨")
            return None
    
    def _initialize_optimizers(self):
        """åˆå§‹åŒ–ä¼˜åŒ–å™¨"""
        print("âš™ï¸ åˆå§‹åŒ–ä¼˜åŒ–å™¨...")
        
        # ç”Ÿæˆå™¨ä¼˜åŒ–å™¨
        if self.training_config.optimizer.lower() == 'adamw':
            self.optimizer = optim.AdamW(
                self.generator.parameters(),
                lr=self.training_config.learning_rate,
                weight_decay=self.training_config.weight_decay,
                betas=(self.training_config.beta1, self.training_config.beta2)
            )
        elif self.training_config.optimizer.lower() == 'adam':
            self.optimizer = optim.Adam(
                self.generator.parameters(),
                lr=self.training_config.learning_rate,
                weight_decay=self.training_config.weight_decay,
                betas=(self.training_config.beta1, self.training_config.beta2)
            )
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ä¼˜åŒ–å™¨: {self.training_config.optimizer}")
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        self._initialize_scheduler()
        
        # æ··åˆç²¾åº¦è®­ç»ƒ
        if self.training_config.mixed_precision:
            self.scaler = torch.cuda.amp.GradScaler()
        else:
            self.scaler = None
        
        print(f"   ä¼˜åŒ–å™¨: {self.training_config.optimizer}")
        print(f"   å­¦ä¹ ç‡: {self.training_config.learning_rate}")
        print(f"   æ··åˆç²¾åº¦: {self.training_config.mixed_precision}")
    
    def _initialize_scheduler(self):
        """åˆå§‹åŒ–å­¦ä¹ ç‡è°ƒåº¦å™¨"""
        if self.training_config.lr_scheduler.lower() == 'cosine':
            self.scheduler = optim.lr_scheduler.CosineAnnealingLR(
                self.optimizer,
                T_max=self.training_config.epochs,
                eta_min=self.training_config.learning_rate * self.training_config.min_lr_ratio
            )
        elif self.training_config.lr_scheduler.lower() == 'step':
            self.scheduler = optim.lr_scheduler.StepLR(
                self.optimizer,
                step_size=self.training_config.epochs // 3,
                gamma=0.5
            )
        else:
            self.scheduler = None
    
    def _initialize_losses(self):
        """åˆå§‹åŒ–æŸå¤±å‡½æ•°"""
        print("ğŸ¯ åˆå§‹åŒ–æŸå¤±å‡½æ•°...")
        
        self.criterion = CompositeLoss(self.config['training']).to(self.device)
        
        print(f"   æŸå¤±ç»„ä»¶æ•°: {len(self.criterion.weights)}")
    
    def _initialize_logging(self):
        """åˆå§‹åŒ–æ—¥å¿—è®°å½•"""
        self.writer = SummaryWriter(log_dir=str(self.log_dir))
        self.step_count = 0
    
    def train(self, train_loader: DataLoader, val_loader: DataLoader = None):
        """
        å¼€å§‹è®­ç»ƒ
        
        Args:
            train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
            val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
        """
        print(f"ğŸš€ å¼€å§‹è®­ç»ƒ - æ€»è½®æ•°: {self.training_config.epochs}")
        
        # è®­ç»ƒå¾ªç¯
        for epoch in range(self.current_epoch, self.training_config.epochs):
            self.current_epoch = epoch
            
            # è®­ç»ƒä¸€ä¸ªepoch
            train_metrics = self._train_epoch(train_loader)
            
            # éªŒè¯ (å¦‚æœéœ€è¦)
            val_metrics = {}
            if val_loader is not None and epoch % self.training_config.val_interval == 0:
                val_metrics = self._validate_epoch(val_loader)
            
            # å­¦ä¹ ç‡è°ƒåº¦
            if self.scheduler is not None:
                self.scheduler.step()
            
            # è®°å½•æ—¥å¿—
            self._log_epoch_metrics(train_metrics, val_metrics)
            
            # ä¿å­˜æ£€æŸ¥ç‚¹
            if epoch % self.training_config.save_interval == 0:
                self._save_checkpoint(train_metrics, val_metrics)
            
            # æ—©åœæ£€æŸ¥
            if self._should_early_stop(val_metrics):
                print(f"â¹ï¸ æ—©åœ: epoch {epoch}")
                break
        
        print("âœ… è®­ç»ƒå®Œæˆ!")
        self._finalize_training()
    
    def _train_epoch(self, train_loader: DataLoader) -> Dict[str, float]:
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.generator.train()
        
        epoch_losses = {}
        epoch_metrics = {}
        
        progress_bar = tqdm(
            train_loader, 
            desc=f"Epoch {self.current_epoch+1}/{self.training_config.epochs}",
            leave=False
        )
        
        for batch_idx, batch in enumerate(progress_bar):
            # è®­ç»ƒä¸€ä¸ªbatch
            batch_losses, batch_metrics = self._train_step(batch)
            
            # ç´¯ç§¯æŸå¤±å’ŒæŒ‡æ ‡
            for key, value in batch_losses.items():
                if key not in epoch_losses:
                    epoch_losses[key] = []
                epoch_losses[key].append(value)
            
            for key, value in batch_metrics.items():
                if key not in epoch_metrics:
                    epoch_metrics[key] = []
                epoch_metrics[key].append(value)
            
            # æ›´æ–°è¿›åº¦æ¡
            progress_bar.set_postfix({
                'loss': f"{batch_losses.get('total_loss', 0):.4f}",
                'sinet_succ': f"{batch_metrics.get('sinet_attack_success_rate', 0):.3f}"
            })
            
            # è®°å½•æ­¥éª¤çº§åˆ«çš„æŒ‡æ ‡
            if batch_idx % 50 == 0:  # æ¯50æ­¥è®°å½•ä¸€æ¬¡
                self._log_step_metrics(batch_losses, batch_metrics)
        
        # è®¡ç®—epochå¹³å‡å€¼
        avg_losses = {k: np.mean(v) for k, v in epoch_losses.items()}
        avg_metrics = {k: np.mean(v) for k, v in epoch_metrics.items()}
        
        return {**avg_losses, **avg_metrics}
    
    def _train_step(self, batch: Dict[str, torch.Tensor]) -> Tuple[Dict[str, float], Dict[str, float]]:
        """è®­ç»ƒä¸€æ­¥"""
        # æ•°æ®ç§»åˆ°è®¾å¤‡
        for key in batch:
            if isinstance(batch[key], torch.Tensor):
                batch[key] = batch[key].to(self.device)
        
        # æ¢¯åº¦æ¸…é›¶
        self.optimizer.zero_grad()
        
        # å‰å‘ä¼ æ’­
        with torch.cuda.amp.autocast(enabled=self.scaler is not None):
            # 1. ç”Ÿæˆè¿·å½©çº¹ç†
            generator_output = self.generator(
                batch['image'], 
                batch['mask'],
                adversarial_gradients=None  # ç¬¬ä¸€æ¬¡å‰å‘ä¼ æ’­
            )
            
            # 2. æ£€æµ‹å™¨è¯„ä¼°
            detectors_output = self._evaluate_detectors(
                generator_output['blended_result']
            )
            
            # 3. è®¡ç®—æŸå¤±
            predictions = {
                'generated_image': generator_output['blended_result'],
                'generated_texture': generator_output['generated_texture'],
                'detectors_output': detectors_output,
                'constraint_outputs': {
                    'constraint_loss': generator_output['constraint_loss']
                }
            }
            
            targets = {
                'original_image': batch['image'],
                'mask': batch['mask']
            }
            
            losses = self.criterion(predictions, targets, self.generator)
            total_loss = losses['total_loss']
        
        # åå‘ä¼ æ’­
        if self.scaler is not None:
            self.scaler.scale(total_loss).backward()
            
            # æ¢¯åº¦è£å‰ª
            self.scaler.unscale_(self.optimizer)
            torch.nn.utils.clip_grad_norm_(self.generator.parameters(), max_norm=1.0)
            
            self.scaler.step(self.optimizer)
            self.scaler.update()
        else:
            total_loss.backward()
            torch.nn.utils.clip_grad_norm_(self.generator.parameters(), max_norm=1.0)
            self.optimizer.step()
        
        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        metrics = self.criterion.compute_metrics(predictions, targets)
        
        # è½¬æ¢ä¸ºæ ‡é‡
        scalar_losses = {k: v.item() if isinstance(v, torch.Tensor) else v 
                        for k, v in losses.items()}
        
        return scalar_losses, metrics
    
    def _evaluate_detectors(self, generated_images: torch.Tensor) -> Dict[str, Any]:
        """è¯„ä¼°æ£€æµ‹å™¨"""
        detectors_output = {}
        
        # SINetæ£€æµ‹
        with torch.no_grad():
            sinet_saliency = self.sinet_detector(generated_images)
            detectors_output['sinet'] = sinet_saliency
        
        # CLIPæ£€æµ‹ (å¦‚æœå¯ç”¨)
        if self.clip_detector is not None:
            with torch.no_grad():
                clip_output = self.clip_detector(generated_images)
                detectors_output['clip'] = clip_output
        
        return detectors_output
    
    def _validate_epoch(self, val_loader: DataLoader) -> Dict[str, float]:
        """éªŒè¯ä¸€ä¸ªepoch"""
        self.generator.eval()
        
        val_losses = {}
        val_metrics = {}
        
        with torch.no_grad():
            for batch in tqdm(val_loader, desc="Validation", leave=False):
                # æ•°æ®ç§»åˆ°è®¾å¤‡
                for key in batch:
                    if isinstance(batch[key], torch.Tensor):
                        batch[key] = batch[key].to(self.device)
                
                # å‰å‘ä¼ æ’­
                generator_output = self.generator(batch['image'], batch['mask'])
                detectors_output = self._evaluate_detectors(generator_output['blended_result'])
                
                # è®¡ç®—æŸå¤±å’ŒæŒ‡æ ‡
                predictions = {
                    'generated_image': generator_output['blended_result'],
                    'generated_texture': generator_output['generated_texture'],
                    'detectors_output': detectors_output,
                    'constraint_outputs': {
                        'constraint_loss': generator_output['constraint_loss']
                    }
                }
                
                targets = {
                    'original_image': batch['image'],
                    'mask': batch['mask']
                }
                
                batch_losses = self.criterion(predictions, targets)
                batch_metrics = self.criterion.compute_metrics(predictions, targets)
                
                # ç´¯ç§¯
                for key, value in batch_losses.items():
                    if key not in val_losses:
                        val_losses[key] = []
                    val_losses[key].append(value.item() if isinstance(value, torch.Tensor) else value)
                
                for key, value in batch_metrics.items():
                    if key not in val_metrics:
                        val_metrics[key] = []
                    val_metrics[key].append(value)
        
        # è®¡ç®—å¹³å‡å€¼
        avg_losses = {f"val_{k}": np.mean(v) for k, v in val_losses.items()}
        avg_metrics = {f"val_{k}": np.mean(v) for k, v in val_metrics.items()}
        
        return {**avg_losses, **avg_metrics}
    
    def _log_step_metrics(self, losses: Dict[str, float], metrics: Dict[str, float]):
        """è®°å½•æ­¥éª¤çº§åˆ«æŒ‡æ ‡"""
        self.step_count += 1
        
        # è®°å½•æŸå¤±
        for key, value in losses.items():
            self.writer.add_scalar(f"step_loss/{key}", value, self.step_count)
        
        # è®°å½•æŒ‡æ ‡
        for key, value in metrics.items():
            self.writer.add_scalar(f"step_metrics/{key}", value, self.step_count)
    
    def _log_epoch_metrics(self, train_metrics: Dict[str, float], 
                          val_metrics: Dict[str, float]):
        """è®°å½•epochçº§åˆ«æŒ‡æ ‡"""
        # è®­ç»ƒæŒ‡æ ‡
        for key, value in train_metrics.items():
            self.writer.add_scalar(f"epoch_train/{key}", value, self.current_epoch)
        
        # éªŒè¯æŒ‡æ ‡
        for key, value in val_metrics.items():
            self.writer.add_scalar(f"epoch_val/{key}", value, self.current_epoch)
        
        # å­¦ä¹ ç‡
        current_lr = self.optimizer.param_groups[0]['lr']
        self.writer.add_scalar("training/learning_rate", current_lr, self.current_epoch)
        
        # æ‰“å°æ—¥å¿—
        print(f"Epoch {self.current_epoch+1}: "
              f"Loss={train_metrics.get('total_loss', 0):.4f}, "
              f"SINet_Success={train_metrics.get('sinet_attack_success_rate', 0):.3f}")
        
        if val_metrics:
            print(f"           Val_Loss={val_metrics.get('val_total_loss', 0):.4f}, "
                  f"Val_SINet_Success={val_metrics.get('val_sinet_attack_success_rate', 0):.3f}")
    
    def _save_checkpoint(self, train_metrics: Dict[str, float], 
                        val_metrics: Dict[str, float]):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        # å½“å‰æ£€æŸ¥ç‚¹
        checkpoint = {
            'epoch': self.current_epoch,
            'model_state_dict': self.generator.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'train_metrics': train_metrics,
            'val_metrics': val_metrics,
            'config': self.config
        }
        
        if self.scheduler is not None:
            checkpoint['scheduler_state_dict'] = self.scheduler.state_dict()
        
        # ä¿å­˜å½“å‰checkpoint
        checkpoint_path = self.checkpoint_dir / f"checkpoint_epoch_{self.current_epoch}.pth"
        torch.save(checkpoint, checkpoint_path)
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        current_metric = val_metrics.get('val_sinet_attack_success_rate', 
                                       train_metrics.get('sinet_attack_success_rate', 0))
        
        if current_metric > self.best_metric:
            self.best_metric = current_metric
            best_path = self.checkpoint_dir / "best_model.pth"
            torch.save(checkpoint, best_path)
            print(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹: æ”»å‡»æˆåŠŸç‡ {current_metric:.3f}")
    
    def _should_early_stop(self, val_metrics: Dict[str, float]) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥æ—©åœ"""
        if not self.training_config.early_stopping:
            return False
        
        # è¿™é‡Œå¯ä»¥å®ç°æ›´å¤æ‚çš„æ—©åœé€»è¾‘
        # æš‚æ—¶è¿”å›False
        return False
    
    def _finalize_training(self):
        """å®Œæˆè®­ç»ƒçš„æ¸…ç†å·¥ä½œ"""
        self.writer.close()
        print(f"ğŸ“Š æœ€ä½³æ”»å‡»æˆåŠŸç‡: {self.best_metric:.3f}")
        print(f"ğŸ’¾ æ¨¡å‹ä¿å­˜åœ¨: {self.checkpoint_dir}")


class CLIPDetectorWrapper(nn.Module):
    """CLIPæ£€æµ‹å™¨åŒ…è£…å™¨"""
    
    def __init__(self, clip_model, preprocess, config):
        super().__init__()
        self.clip_model = clip_model
        self.preprocess = preprocess
        self.config = config
        
        # é¢„å¤„ç†æ–‡æœ¬æç¤º
        positive_text = clip.tokenize(config.positive_prompts).to(clip_model.device)
        negative_text = clip.tokenize(config.negative_prompts).to(clip_model.device)
        
        with torch.no_grad():
            self.positive_features = clip_model.encode_text(positive_text)
            self.negative_features = clip_model.encode_text(negative_text)
            
            # å½’ä¸€åŒ–
            self.positive_features = self.positive_features / self.positive_features.norm(dim=-1, keepdim=True)
            self.negative_features = self.negative_features / self.negative_features.norm(dim=-1, keepdim=True)
    
    def forward(self, images):
        """
        Args:
            images: [B, 3, H, W] è¾“å…¥å›¾åƒ (-1 to 1 or 0 to 1)
            
        Returns:
            output: dict with similarities
        """
        # è½¬æ¢å›¾åƒæ ¼å¼
        if images.min() < 0:
            images = (images + 1) / 2  # [-1,1] -> [0,1]
        
        # CLIPå›¾åƒç¼–ç 
        with torch.no_grad():
            image_features = self.clip_model.encode_image(images)
            image_features = image_features / image_features.norm(dim=-1, keepdim=True)
            
            # è®¡ç®—ç›¸ä¼¼åº¦
            positive_sim = (image_features @ self.positive_features.T).mean(dim=-1)
            negative_sim = (image_features @ self.negative_features.T).mean(dim=-1)
        
        return {
            'positive_similarity': positive_sim,
            'negative_similarity': negative_sim
        }


def create_trainer_from_config(config_path: str = None) -> AdversarialTrainer:
    """ä»é…ç½®æ–‡ä»¶åˆ›å»ºè®­ç»ƒå™¨"""
    if config_path is not None:
        # ä»æ–‡ä»¶åŠ è½½é…ç½®
        # è¿™é‡Œå¯ä»¥æ·»åŠ é…ç½®æ–‡ä»¶åŠ è½½é€»è¾‘
        pass
    
    # ä½¿ç”¨é»˜è®¤é…ç½®
    config = get_default_config()
    
    # æ£€æµ‹è®¾å¤‡
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    trainer = AdversarialTrainer(config, device)
    
    return trainer


if __name__ == "__main__":
    # æµ‹è¯•è®­ç»ƒå™¨
    print("ğŸ§ª æµ‹è¯•è®­ç»ƒå™¨...")
    
    trainer = create_trainer_from_config()
    
    print("âœ… è®­ç»ƒå™¨æµ‹è¯•å®Œæˆ")
    print(f"   ç”Ÿæˆå™¨å‚æ•°: {sum(p.numel() for p in trainer.generator.parameters()) / 1e6:.1f}M")
    print(f"   è®¾å¤‡: {trainer.device}")
